package agents

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/mshogin/agents/internal/domain/models"
	"github.com/mshogin/agents/internal/domain/services"
)

// RetrievalExecutorAgent executes retrieval plans and queries against data sources.
//
// Design Principles:
// - Executes queries generated by RetrievalPlannerAgent
// - Supports multiple data sources (GitLab, YouTrack, etc.)
// - Handles parallel execution for multiple queries
// - Graceful error handling (partial failures don't block pipeline)
// - Tracks execution time and success/failure metrics
//
// Input Requirements:
// - retrieval.plans: Retrieval plans from RetrievalPlannerAgent
// - retrieval.queries: Generated queries to execute
//
// Output:
// - retrieval.artifacts: Retrieved data from all sources
//
// Capabilities:
// - Parallel query execution for performance
// - Timeout handling per query
// - Error recovery (failed queries don't fail entire agent)
// - Source health checking
type RetrievalExecutorAgent struct {
	id             string
	dataSource     services.DataSourceClient
	maxConcurrency int
	queryTimeout   time.Duration
}

// NewRetrievalExecutorAgent creates a new retrieval executor agent.
//
// Parameters:
// - dataSource: Client for executing queries (injected via DI)
// - maxConcurrency: Maximum number of parallel queries (default: 5)
// - queryTimeout: Timeout per query (default: 30s)
func NewRetrievalExecutorAgent(dataSource services.DataSourceClient, maxConcurrency int, queryTimeout time.Duration) *RetrievalExecutorAgent {
	if maxConcurrency <= 0 {
		maxConcurrency = 5 // Default
	}
	if queryTimeout == 0 {
		queryTimeout = 30 * time.Second // Default
	}

	return &RetrievalExecutorAgent{
		id:             "retrieval_executor",
		dataSource:     dataSource,
		maxConcurrency: maxConcurrency,
		queryTimeout:   queryTimeout,
	}
}

// AgentID returns the unique identifier for this agent.
func (a *RetrievalExecutorAgent) AgentID() string {
	return a.id
}

// Preconditions returns the list of context keys required before execution.
func (a *RetrievalExecutorAgent) Preconditions() []string {
	return []string{
		"retrieval.plans",
		"retrieval.queries",
	}
}

// Postconditions returns the list of context keys guaranteed after execution.
func (a *RetrievalExecutorAgent) Postconditions() []string {
	return []string{
		"retrieval.artifacts",
	}
}

// Execute runs retrieval queries and collects artifacts.
func (a *RetrievalExecutorAgent) Execute(ctx context.Context, agentContext *models.AgentContext) (*models.AgentContext, error) {
	startTime := time.Now()

	// Clone context
	newContext, err := agentContext.Clone()
	if err != nil {
		return nil, fmt.Errorf("failed to clone context: %w", err)
	}

	// Validate preconditions
	if err := a.validatePreconditions(newContext); err != nil {
		return nil, fmt.Errorf("precondition validation failed: %w", err)
	}

	// Extract queries
	queries := newContext.Retrieval.Queries

	// Store detailed agent trace
	agentTrace := map[string]interface{}{
		"agent_id":         a.id,
		"input_queries":    queries,
		"queries_count":    len(queries),
		"max_concurrency":  a.maxConcurrency,
		"query_timeout_ms": a.queryTimeout.Milliseconds(),
	}

	// Execute queries in parallel (with concurrency limit)
	artifacts, errors := a.executeQueriesParallel(ctx, queries)
	agentTrace["artifacts_retrieved"] = len(artifacts)
	agentTrace["errors_count"] = len(errors)
	if len(errors) > 0 {
		agentTrace["errors"] = errors
	}

	// Write artifacts to context
	newContext.Retrieval.Artifacts = artifacts

	// Track execution errors (non-fatal)
	if len(errors) > 0 {
		a.recordErrors(newContext, errors)
	}

	// Store final output in trace
	agentTrace["output_artifacts"] = artifacts

	// Store agent trace in LLM cache
	if newContext.LLM == nil {
		newContext.LLM = &models.LLMContext{
			Cache: make(map[string]interface{}),
		}
	}
	if newContext.LLM.Cache == nil {
		newContext.LLM.Cache = make(map[string]interface{})
	}
	if traces, ok := newContext.LLM.Cache["agent_traces"].([]interface{}); ok {
		newContext.LLM.Cache["agent_traces"] = append(traces, agentTrace)
	} else {
		newContext.LLM.Cache["agent_traces"] = []interface{}{agentTrace}
	}

	// Track execution
	duration := time.Since(startTime)
	status := "success"
	if len(artifacts) == 0 && len(queries) > 0 {
		status = "partial_failure" // No artifacts retrieved
		agentTrace["status"] = status
	}
	a.recordAgentRun(newContext, duration, status, nil)

	return newContext, nil
}

// validatePreconditions checks required context keys.
func (a *RetrievalExecutorAgent) validatePreconditions(ctx *models.AgentContext) error {
	if ctx.Retrieval == nil {
		return fmt.Errorf("retrieval context is nil")
	}

	if len(ctx.Retrieval.Plans) == 0 {
		return fmt.Errorf("no retrieval plans found (required: retrieval.plans)")
	}

	if len(ctx.Retrieval.Queries) == 0 {
		return fmt.Errorf("no queries found (required: retrieval.queries)")
	}

	return nil
}

// executeQueriesParallel executes queries in parallel with concurrency control.
func (a *RetrievalExecutorAgent) executeQueriesParallel(ctx context.Context, queries []models.Query) ([]models.Artifact, []error) {
	// Semaphore for concurrency control
	sem := make(chan struct{}, a.maxConcurrency)
	var wg sync.WaitGroup

	// Result channels
	artifactsChan := make(chan []models.Artifact, len(queries))
	errorsChan := make(chan error, len(queries))

	// Execute each query in goroutine
	for _, query := range queries {
		wg.Add(1)
		go func(q models.Query) {
			defer wg.Done()

			// Acquire semaphore
			sem <- struct{}{}
			defer func() { <-sem }()

			// Execute query with timeout
			queryCtx, cancel := context.WithTimeout(ctx, a.queryTimeout)
			defer cancel()

			artifacts, err := a.executeQuery(queryCtx, q)
			if err != nil {
				errorsChan <- fmt.Errorf("query %s failed: %w", q.ID, err)
				return
			}

			artifactsChan <- artifacts
		}(query)
	}

	// Wait for all queries to complete
	wg.Wait()
	close(artifactsChan)
	close(errorsChan)

	// Collect results
	allArtifacts := []models.Artifact{}
	for artifacts := range artifactsChan {
		allArtifacts = append(allArtifacts, artifacts...)
	}

	// Collect errors
	allErrors := []error{}
	for err := range errorsChan {
		allErrors = append(allErrors, err)
	}

	return allArtifacts, allErrors
}

// executeQuery executes a single query against the data source.
func (a *RetrievalExecutorAgent) executeQuery(ctx context.Context, query models.Query) ([]models.Artifact, error) {
	// Handle nil dataSource (graceful degradation)
	if a.dataSource == nil {
		// Return mock artifact to allow pipeline to continue
		return []models.Artifact{
			{
				ID:      fmt.Sprintf("mock-%s", query.ID),
				Source:  query.Source,
				Type:    "mock_data",
				Content: map[string]interface{}{
					"query":   query.QueryString,
					"message": "No data source configured - using mock data",
					"note":    "Connect MCP servers for real data retrieval",
				},
			},
		}, nil
	}

	// Execute query using data source client
	artifacts, err := a.dataSource.ExecuteQuery(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("data source query failed: %w", err)
	}

	return artifacts, nil
}

// recordErrors logs errors in diagnostics context.
func (a *RetrievalExecutorAgent) recordErrors(ctx *models.AgentContext, errors []error) {
	if ctx.Diagnostics == nil {
		ctx.Diagnostics = &models.DiagnosticsContext{}
	}

	for _, err := range errors {
		ctx.Diagnostics.Errors = append(ctx.Diagnostics.Errors, models.ErrorReport{
			Timestamp: time.Now(),
			AgentID:   a.id,
			Message:   err.Error(),
			Severity:  "warning", // Non-fatal
		})
	}
}

// recordAgentRun records execution in audit trail.
func (a *RetrievalExecutorAgent) recordAgentRun(ctx *models.AgentContext, duration time.Duration, status string, err error) {
	run := models.AgentRun{
		Timestamp:  time.Now(),
		AgentID:    a.id,
		Status:     status,
		DurationMS: duration.Milliseconds(),
		KeysWritten: []string{
			"retrieval.artifacts",
		},
	}

	if err != nil {
		run.Error = err.Error()
	}

	if ctx.Audit == nil {
		ctx.Audit = &models.AuditContext{}
	}

	ctx.Audit.AgentRuns = append(ctx.Audit.AgentRuns, run)

	// Update performance metrics
	if ctx.Diagnostics == nil {
		ctx.Diagnostics = &models.DiagnosticsContext{
			Performance: &models.PerformanceData{},
		}
	}

	if ctx.Diagnostics.Performance.AgentMetrics == nil {
		ctx.Diagnostics.Performance.AgentMetrics = make(map[string]*models.AgentMetrics)
	}

	ctx.Diagnostics.Performance.AgentMetrics[a.id] = &models.AgentMetrics{
		DurationMS: duration.Milliseconds(),
		LLMCalls:   0, // No LLM calls
		Status:     status,
	}
}

// GetMetadata returns agent metadata.
func (a *RetrievalExecutorAgent) GetMetadata() services.AgentMetadata {
	return services.AgentMetadata{
		ID:          a.id,
		Name:        "Retrieval Executor Agent",
		Description: "Executes retrieval queries against data sources (GitLab, YouTrack) and collects artifacts",
		Version:     "1.0.0",
		Author:      "ADK LLM Proxy",
		Tags:        []string{"retrieval", "execution", "data-sources", "parallel", "gitlab", "youtrack"},
		Dependencies: []string{"retrieval_planner"},
	}
}

// GetCapabilities returns agent capabilities.
func (a *RetrievalExecutorAgent) GetCapabilities() services.AgentCapabilities {
	return services.AgentCapabilities{
		SupportsParallelExecution: true,  // Can run queries in parallel internally
		SupportsRetry:             true,  // Can retry on failure
		RequiresLLM:               false, // No LLM needed
		IsDeterministic:           false, // Results depend on external data sources
		EstimatedDuration:         3000,  // ~3s for typical queries (can vary widely)
	}
}
